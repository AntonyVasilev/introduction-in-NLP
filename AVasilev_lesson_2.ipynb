{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание к уроку 2\n",
    "Исполнитель: Васильев А.\n",
    "\n",
    "Продолжим обработку данных с Твиттера. \n",
    "\n",
    "#### Задания:\n",
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    " * Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    " * Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    " * Исключим стоп-слова с помощью stop_words='english'. \n",
    " * Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n",
    " \n",
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    " * Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    " * Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    " * Исключим стоп-слова с помощью stop_words='english'.\n",
    " * Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n",
    " \n",
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import re\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combine_df.pickle', 'rb') as f:\n",
    "    combine_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet  \\\n",
       "id                                                             \n",
       "1     0.0  when father is dysfunctional and is so selfish...   \n",
       "2     0.0  thanks for lyft credit cannot use cause they d...   \n",
       "3     0.0                                bihday your majesty   \n",
       "4     0.0    model love you take with you all the time in ur   \n",
       "5     0.0                  factsguide society now motivation   \n",
       "\n",
       "                                          tweet_token  \\\n",
       "id                                                      \n",
       "1   [when, father, is, dysfunctional, and, is, so,...   \n",
       "2   [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "3                             [bihday, your, majesty]   \n",
       "4   [model, love, you, take, with, you, all, the, ...   \n",
       "5              [factsguide, society, now, motivation]   \n",
       "\n",
       "                                 tweet_token_filtered  \\\n",
       "id                                                      \n",
       "1   [father, dysfunctional, selfish, drags, kids, ...   \n",
       "2   [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "3                                   [bihday, majesty]   \n",
       "4                       [model, love, take, time, ur]   \n",
       "5                   [factsguide, society, motivation]   \n",
       "\n",
       "                                        tweet_stemmed  \\\n",
       "id                                                      \n",
       "1   [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "2   [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "3                                   [bihday, majesti]   \n",
       "4                       [model, love, take, time, ur]   \n",
       "5                         [factsguid, societi, motiv]   \n",
       "\n",
       "                                     tweet_lemmatized  \n",
       "id                                                     \n",
       "1   [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "2   [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "3                                   [bihday, majesty]  \n",
       "4                       [model, love, take, time, ur]  \n",
       "5                   [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = combine_df.set_index('id')\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Использую CountVectorizer для создания мешков слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 'tweet_stemmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec_st = CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33084</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21105</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n",
       "33084    0        0       0        0    0       0      0       0   0      0   \n",
       "7118     0        0       0        0    0       0      0       0   0      0   \n",
       "21105    0        0       0        0    0       0      0       0   0      0   \n",
       "32311    0        0       0        0    0       0      0       0   0      0   \n",
       "45322    0        0       0        0    0       0      0       0   0      0   \n",
       "\n",
       "       ...  yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "33084  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "7118   ...     0     0          0   0     0     0      0       0   0      0  \n",
       "21105  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "32311  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "45322  ...     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_stemmed_c_vec = c_vec_st.fit_transform([' '.join(sent) for sent in combine_df.tweet_stemmed])\n",
    "# Обображаю Bag-of-Words как DataFrame\n",
    "pd.DataFrame(bow_tweet_stemmed_c_vec.toarray(), columns = c_vec_st.get_feature_names()).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 'tweet_lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec_lm = CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adult</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36617</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "29706     0           0        0    0       0      0         0      0    0   \n",
       "11440     0           0        0    0       0      0         0      0    0   \n",
       "47342     0           0        0    0       0      0         0      0    0   \n",
       "36617     0           0        0    0       0      0         0      0    0   \n",
       "22699     0           0        0    0       0      0         0      0    0   \n",
       "\n",
       "       adult  ...  year  yes  yesterday  yo  yoga  york  young  youtube  yr  \\\n",
       "29706      0  ...     0    0          0   0     0     0      0        0   0   \n",
       "11440      0  ...     0    0          0   0     0     0      0        0   0   \n",
       "47342      0  ...     0    0          0   0     0     0      0        0   0   \n",
       "36617      0  ...     0    0          0   0     0     0      0        0   0   \n",
       "22699      0  ...     0    0          0   0     0     0      0        0   0   \n",
       "\n",
       "       yummy  \n",
       "29706      0  \n",
       "11440      0  \n",
       "47342      0  \n",
       "36617      0  \n",
       "22699      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_lemmatized_c_vec = c_vec_lm.fit_transform([' '.join(sent) for sent in combine_df.tweet_lemmatized])\n",
    "# Обображаю Bag-of-Words как DataFrame\n",
    "pd.DataFrame(bow_tweet_lemmatized_c_vec.toarray(), columns = c_vec_lm.get_feature_names()).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Использую CountVectorizer для создания мешков слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 'tweet_stemmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec_st = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abl  absolut  accept  account  act  action  actor  actual   ad  adapt  \\\n",
       "23125  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "27539  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "7355   0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "5800   0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "39510  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n",
       "\n",
       "       ...      yeah  year  yesterday   yo  yoga  york  young  youtub   yr  \\\n",
       "23125  ...  0.617422   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0   \n",
       "27539  ...  0.000000   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0   \n",
       "7355   ...  0.000000   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0   \n",
       "5800   ...  0.000000   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0   \n",
       "39510  ...  0.000000   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0   \n",
       "\n",
       "       yummi  \n",
       "23125    0.0  \n",
       "27539    0.0  \n",
       "7355     0.0  \n",
       "5800     0.0  \n",
       "39510    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_stemmed_tf_vec =tf_vec_st.fit_transform([' '.join(sent) for sent in combine_df.tweet_stemmed])\n",
    "# Обображаю Bag-of-Words как DataFrame\n",
    "pd.DataFrame(bow_tweet_stemmed_tf_vec.toarray(), columns = tf_vec_st.get_feature_names()).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 'tweet_lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec_lm = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>adult</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46331</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10588</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n",
       "46376   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "46331   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "7673    0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "10588   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "25216   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n",
       "\n",
       "       adult  ...  year  yes  yesterday   yo  yoga  york  young  youtube   yr  \\\n",
       "46376    0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "46331    0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "7673     0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "10588    0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "25216    0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0  0.0   \n",
       "\n",
       "       yummy  \n",
       "46376    0.0  \n",
       "46331    0.0  \n",
       "7673     0.0  \n",
       "10588    0.0  \n",
       "25216    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_lemmatized_tf_vec = tf_vec_lm.fit_transform([' '.join(sent) for sent in combine_df.tweet_lemmatized])\n",
    "# Обображаю Bag-of-Words как DataFrame\n",
    "pd.DataFrame(bow_tweet_lemmatized_tf_vec.toarray(), columns = tf_vec_lm.get_feature_names()).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаю данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаю датафрейм\n",
    "corpus_df = pd.DataFrame()\n",
    "corpus_df['text'] = texts\n",
    "corpus_df['label'] = labels\n",
    "corpus_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(corpus_df['text'], corpus_df['label'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_valid = encoder.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7376"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer (stemmed)\n",
    "X_train_count_vec_st =  c_vec_st.transform(X_train)\n",
    "X_valid_count_vec_st =  c_vec_st.transform(X_valid)\n",
    "\n",
    "clf_count_st = LogisticRegression(max_iter=200)\n",
    "clf_count_st.fit(X_train_count_vec_st, y_train)\n",
    "preds_count_st = clf_count_st.predict(X_valid_count_vec_st)\n",
    "\n",
    "accuracy_score(y_valid, preds_count_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5456"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer (lemmatized)\n",
    "X_train_count_vec_lm =  c_vec_lm.transform(X_train)\n",
    "X_valid_count_vec_lm =  c_vec_lm.transform(X_valid)\n",
    "\n",
    "clf_count_lm = LogisticRegression(max_iter=200)\n",
    "clf_count_lm.fit(X_train_count_vec_lm, y_train)\n",
    "preds_count_lm = clf_count_st.predict(X_valid_count_vec_lm)\n",
    "\n",
    "accuracy_score(y_valid, preds_count_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer (stemmed)\n",
    "X_train_tfidf_vec_st = tf_vec_st.transform(X_train)\n",
    "X_valid_tfidf_vec_st = tf_vec_st.transform(X_valid)\n",
    "\n",
    "clf_tfidf_st = LogisticRegression()\n",
    "clf_tfidf_st.fit(X_train_tfidf_vec_st, y_train)\n",
    "preds_tfidf_st = clf_tfidf_st.predict(X_valid_count_vec_st)\n",
    "\n",
    "accuracy_score(y_valid, preds_tfidf_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer (lemmatized)\n",
    "X_train_tfidf_vec_lm = tf_vec_lm.transform(X_train)\n",
    "X_valid_tfidf_vec_lm = tf_vec_lm.transform(X_valid)\n",
    "\n",
    "clf_tfidf_lm = LogisticRegression()\n",
    "clf_tfidf_lm.fit(X_train_tfidf_vec_lm, y_train)\n",
    "preds_tfidf_lm = clf_tfidf_lm.predict(X_valid_count_vec_lm)\n",
    "\n",
    "accuracy_score(y_valid, preds_tfidf_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df_list = [0.8, 0.9, 1.0]\n",
    "max_features_list = [500, 800, 1000, 2000, 3000, 4000, 5000]\n",
    "min_df_list = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_list = []\n",
    "for max_df, max_features, min_df in product(max_df_list, max_features_list, min_df_list):\n",
    "    c_vec_st_ = CountVectorizer(max_df=max_df, max_features=max_features, \n",
    "                                min_df=min_df, stop_words='english')\n",
    "    c_vec_st_.fit([' '.join(sent) for sent in combine_df.tweet_stemmed])\n",
    "    X_train_count_vec_st_ =  c_vec_st_.transform(X_train)\n",
    "    X_valid_count_vec_st_ =  c_vec_st_.transform(X_valid)\n",
    "    clf_count_st_ = LogisticRegression(max_iter=200)\n",
    "    clf_count_st_.fit(X_train_count_vec_st_, y_train)\n",
    "    preds_count_st_ = clf_count_st_.predict(X_valid_count_vec_st_)\n",
    "    result_list.append({'max_features': max_features,\n",
    "                        'max_df': max_df, 'min_df': min_df, \n",
    "                        'vect_type': 'count_stemmed', \n",
    "                        'accuracy': accuracy_score(y_valid, preds_count_st_)})\n",
    "    \n",
    "    c_vec_lm_ = CountVectorizer(max_df=max_df, max_features=max_features, \n",
    "                                min_df=min_df, stop_words='english')\n",
    "    c_vec_lm_.fit([' '.join(sent) for sent in combine_df.tweet_lemmatized])\n",
    "    X_train_count_vec_lm_ =  c_vec_lm_.transform(X_train)\n",
    "    X_valid_count_vec_lm_ =  c_vec_lm_.transform(X_valid)\n",
    "    clf_count_lm_ = LogisticRegression(max_iter=200)\n",
    "    clf_count_lm_.fit(X_train_count_vec_lm_, y_train)\n",
    "    preds_count_lm_ = clf_count_lm_.predict(X_valid_count_vec_lm_)\n",
    "    result_list.append({'max_features': max_features,\n",
    "                        'max_df': max_df, 'min_df': min_df, \n",
    "                        'vect_type': 'count_lemmatized', \n",
    "                        'accuracy': accuracy_score(y_valid, preds_count_lm_)})\n",
    "    \n",
    "    tf_vec_st_ = TfidfVectorizer(max_df=max_df, max_features=max_features, \n",
    "                                 min_df=min_df, stop_words='english')\n",
    "    tf_vec_st_.fit([' '.join(sent) for sent in combine_df.tweet_stemmed])\n",
    "    X_train_tfidf_vec_st_ =  tf_vec_st_.transform(X_train)\n",
    "    X_valid_tfidf_vec_st_ =  tf_vec_st_.transform(X_valid)\n",
    "    clf_tfidf_st_ = LogisticRegression(max_iter=200)\n",
    "    clf_tfidf_st_.fit(X_train_tfidf_vec_st_, y_train)\n",
    "    preds_tfidf_st_ = clf_tfidf_st_.predict(X_valid_tfidf_vec_st_)\n",
    "    result_list.append({'max_features': max_features,\n",
    "                        'max_df': max_df, 'min_df': min_df, \n",
    "                        'vect_type': 'tfidf_stemmed', \n",
    "                        'accuracy': accuracy_score(y_valid, preds_tfidf_st_)})\n",
    "    \n",
    "    tf_vec_lm_ = TfidfVectorizer(max_df=max_df, max_features=max_features, \n",
    "                                 min_df=min_df, stop_words='english')\n",
    "    tf_vec_lm_.fit([' '.join(sent) for sent in combine_df.tweet_lemmatized])\n",
    "    X_train_tfidf_vec_lm_ =  tf_vec_lm_.transform(X_train)\n",
    "    X_valid_tfidf_vec_lm_ =  tf_vec_lm_.transform(X_valid)\n",
    "    clf_tfidf_lm_ = LogisticRegression(max_iter=200)\n",
    "    clf_tfidf_lm_.fit(X_train_tfidf_vec_lm_, y_train)\n",
    "    preds_tfidf_lm_ = clf_tfidf_lm_.predict(X_valid_tfidf_vec_lm_)\n",
    "    result_list.append({'max_features': max_features,\n",
    "                        'max_df': max_df, 'min_df': min_df, \n",
    "                        'vect_type': 'tfidf_lemmatized', \n",
    "                        'accuracy': accuracy_score(y_valid, preds_tfidf_lm_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_list.json', 'w') as f:\n",
    "    json.dump(result_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>vect_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>count_stemmed</td>\n",
       "      <td>0.7052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>count_lemmatized</td>\n",
       "      <td>0.7308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>tfidf_stemmed</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>tfidf_lemmatized</td>\n",
       "      <td>0.7348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>count_stemmed</td>\n",
       "      <td>0.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  max_df  min_df         vect_type  accuracy\n",
       "0           500     0.8       1     count_stemmed    0.7052\n",
       "1           500     0.8       1  count_lemmatized    0.7308\n",
       "2           500     0.8       1     tfidf_stemmed    0.7200\n",
       "3           500     0.8       1  tfidf_lemmatized    0.7348\n",
       "4           500     0.8       2     count_stemmed    0.7052"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_features                5000\n",
       "max_df                       0.8\n",
       "min_df                         2\n",
       "vect_type       count_lemmatized\n",
       "accuracy                  0.8372\n",
       "Name: 77, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.iloc[np.argmax(result_df.accuracy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>vect_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>count_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>tfidf_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>count_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>tfidf_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>count_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>tfidf_lemmatized</td>\n",
       "      <td>0.8372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_features  max_df  min_df         vect_type  accuracy\n",
       "77           5000     0.8       2  count_lemmatized    0.8372\n",
       "79           5000     0.8       2  tfidf_lemmatized    0.8372\n",
       "161          5000     0.9       2  count_lemmatized    0.8372\n",
       "163          5000     0.9       2  tfidf_lemmatized    0.8372\n",
       "245          5000     1.0       2  count_lemmatized    0.8372\n",
       "247          5000     1.0       2  tfidf_lemmatized    0.8372"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[result_df.accuracy == 0.8372, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vec_lm = TfidfVectorizer(max_df=0.8, max_features=5000, \n",
    "                             min_df=2, stop_words='english')\n",
    "tf_vec_lm.fit([' '.join(sent) for sent in combine_df.tweet_lemmatized])\n",
    "X_train_tfidf_vec_lm =  tf_vec_lm.transform(X_train)\n",
    "X_valid_tfidf_vec_lm =  tf_vec_lm.transform(X_valid)\n",
    "clf_tfidf_lm = LogisticRegression(max_iter=200)\n",
    "clf_tfidf_lm.fit(X_train_tfidf_vec_lm, y_train)\n",
    "preds_tfidf_lm = clf_tfidf_lm.predict(X_valid_tfidf_vec_lm)\n",
    "accuracy_score(y_valid, preds_tfidf_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ = PCA(n_components=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA: (7500, 5000), after PCA: (7500, 500)\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_vec_lm_pca = pca_.fit_transform(X_train_tfidf_vec_lm.toarray())\n",
    "X_valid_tfidf_vec_lm_pca = pca_.transform(X_valid_tfidf_vec_lm.toarray())\n",
    "print(f'Before PCA: {X_train_tfidf_vec_lm.shape}, after PCA: {X_train_tfidf_vec_lm_pca.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tfidf_lm_pca = LogisticRegression(max_iter=200)\n",
    "clf_tfidf_lm_pca.fit(X_train_tfidf_vec_lm_pca, y_train)\n",
    "preds_tfidf_lm_pca = clf_tfidf_lm_pca.predict(X_valid_tfidf_vec_lm_pca)\n",
    "accuracy_score(y_valid, preds_tfidf_lm_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = [100, 300, 500, 800, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca_results = []\n",
    "for n_components in n_components_list:\n",
    "    pca_ = PCA(n_components=n_components)\n",
    "    X_train_tfidf_vec_lm_pca_ = pca_.fit_transform(X_train_tfidf_vec_lm.toarray())\n",
    "    X_valid_tfidf_vec_lm_pca_ = pca_.transform(X_valid_tfidf_vec_lm.toarray())\n",
    "    clf_tfidf_lm_pca_ = LogisticRegression(max_iter=200)\n",
    "    clf_tfidf_lm_pca_.fit(X_train_tfidf_vec_lm_pca_, y_train)\n",
    "    preds_tfidf_lm_pca_ = clf_tfidf_lm_pca_.predict(X_valid_tfidf_vec_lm_pca_)\n",
    "    pca_results.append({'n_components': n_components,\n",
    "                       'accuracy': accuracy_score(y_valid, preds_tfidf_lm_pca_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pca_results.json', 'w') as f:\n",
    "    json.dump(pca_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>0.8284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800</td>\n",
       "      <td>0.8264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.8292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  accuracy\n",
       "0           100    0.8004\n",
       "1           300    0.8284\n",
       "2           500    0.8228\n",
       "3           800    0.8264\n",
       "4          1000    0.8292"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df = pd.DataFrame(pca_results)\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
