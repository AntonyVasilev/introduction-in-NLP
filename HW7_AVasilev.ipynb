{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwAdrrlks_ZJ"
   },
   "source": [
    "## Практическое задание к уроку 7\n",
    "Исполнитель: Васильев Антон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации\n",
    "2. Рассмотреть 2-а варианта сеточек\n",
    "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
    "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
    "\n",
    "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUCk-5M2yg3S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1590650140159,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "KBSf-OfDzWOI",
    "outputId": "8b28d120-8490-44b3-cb86-6a1267ef1ad1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5908,
     "status": "ok",
     "timestamp": 1590650166113,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "LuZtq9cwIvMt",
    "outputId": "91c8b4fb-a01b-4bbb-c3a9-2dc08922f193"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204150</td>\n",
       "      <td>Тектоника и рельеф-самое ужасное в мире мучение(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204151</td>\n",
       "      <td>Ходили запускать шар желаний, но у нас не полу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204152</td>\n",
       "      <td>Хочу лето только ради того, что бы направить н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204153</td>\n",
       "      <td>RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204154</td>\n",
       "      <td>RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  204150   Тектоника и рельеф-самое ужасное в мире мучение(\n",
       "1  204151  Ходили запускать шар желаний, но у нас не полу...\n",
       "2  204152  Хочу лето только ради того, что бы направить н...\n",
       "3  204153  RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...\n",
       "4  204154  RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1590650173083,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "_9l0iHhaI0O1",
    "outputId": "4b7f24ee-222f-464b-e669-d653138571d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 170 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, _, hist = plt.hist(df_train.text.apply(lambda text: len(text.split())), bins='auto')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H5tFUEMCE7d"
   },
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 30\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEyvOxoOJDTP"
   },
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: stop-words\n",
      "  Building wheel for stop-words (setup.py): started\n",
      "  Building wheel for stop-words (setup.py): finished with status 'done'\n",
      "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=75c043c88ad02633f123a2d6a34bc00699c13d0e56eb1c0e2ff5bce90fd5bce4\n",
      "  Stored in directory: c:\\users\\avasilev\\appdata\\local\\pip\\cache\\wheels\\eb\\03\\0d\\3bd31c983789aeb0b4d5e2ca48590288d9db1586cf5f225062\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install stop_words\n",
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4o9QgmWI3Pw"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"text\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10183,
     "status": "ok",
     "timestamp": 1590650264825,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "Hed2ySbwJH6B",
    "outputId": "66a75988-b4e3-45aa-a483-adbdc766db03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AVasilev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJ8T0fwYJYJX"
   },
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXOLVK1tJLT8"
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qCQH5nIJoiB"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1590650396521,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "bRQ-6wwjJrGo",
    "outputId": "ba8ebf9e-c6aa-4703-b54f-39b561e33493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хотеть',\n",
       " 'знать',\n",
       " 'ян',\n",
       " 'мочь',\n",
       " 'новый',\n",
       " 'любить',\n",
       " 'завтра',\n",
       " 'мой',\n",
       " 'хороший',\n",
       " 'делать']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top.remove('rt')\n",
    "tokens_filtered_top.remove('d')\n",
    "tokens_filtered_top.remove('3')\n",
    "tokens_filtered_top.remove('2')\n",
    "tokens_filtered_top.remove('5')\n",
    "tokens_filtered_top.remove('4')\n",
    "tokens_filtered_top.remove('оо')\n",
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OULZgvkJzpj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqHlf5nNJ2hl"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"text\"]], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1590650625870,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "lI4NUg_TJ6NK",
    "outputId": "5d29285d-6c2e-4c34-f307-c2e9c3c12631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181467, 30)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1590650628713,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "9QlLvXd9KDf3",
    "outputId": "0355c6dc-b479-4031-bf7d-54f158607906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       206, 441, 163,   7])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPool1D, MaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.utils import get_file, to_categorical\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаю предобученную модель tayga_upos_skipgram_300_2_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://vectors.nlpl.eu/repository/20/185.zip\n",
      "639270912/639268566 [==============================] - 181s 0us/step\n",
      "639279104/639268566 [==============================] - 181s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_path = get_file(\n",
    "    \"185.zip\",\n",
    "    \"http://vectors.nlpl.eu/repository/20/185.zip\",\n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/AVasilev/.keras/datasets')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path(data_path).parent\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This archive is part of the NLPL Word Vectors Repository (http://vectors.nlpl.eu/repository/), version 2.0, published on Friday, December 27, 2019.\n",
      "Please see the file 'meta.json' in this archive and the overall repository metadata file http://vectors.nlpl.eu/repository/20.json for additional information.\n",
      "The life-time identifier for this model is:\n",
      "http://vectors.nlpl.eu/repository/20/185.zip\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir / \"README\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"algorithm\": {\n",
      "        \"command\": null,\n",
      "        \"id\": 0,\n",
      "        \"name\": \"Gensim Continuous Skipgram\",\n",
      "        \"tool\": \"Gensim\",\n",
      "        \"url\": \"https://github.com/RaRe-Technologies/gensim\",\n",
      "        \"version\": \"3.6\"\n",
      "    },\n",
      "    \"contents\": [\n",
      "        {\n",
      "            \"filename\": \"model.txt\",\n",
      "            \"format\": \"text\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"model.bin\",\n",
      "            \"format\": \"data\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"meta.json\",\n",
      "            \"format\": \"json\"\n",
      "        }\n",
      "    ],\n",
      "    \"corpus\": [\n",
      "        {\n",
      "            \"NER\": true,\n",
      "            \"case preserved\": false,\n",
      "            \"description\": \"Taiga corpus\",\n",
      "            \"id\": 93,\n",
      "            \"language\": \"rus\",\n",
      "            \"lemmatized\": true,\n",
      "            \"public\": true,\n",
      "            \"stop words removal\": \"functional PoS\",\n",
      "            \"tagger\": \"UDPipe 1.2\",\n",
      "            \"tagset\": \"UPoS\",\n",
      "            \"tokens\": 4867000000,\n",
      "            \"url\": \"https://tatianashavrina.github.io/taiga_site/\"\n",
      "        }\n",
      "    ],\n",
      "    \"creators\": [\n",
      "        {\n",
      "            \"email\": \"andreku@ifi.uio.no\",\n",
      "            \"name\": \"Andrey Kutuzov\"\n",
      "        }\n",
      "    ],\n",
      "    \"dimensions\": 300,\n",
      "    \"documentation\": [\n",
      "        \"https://rusvectores.org\"\n",
      "    ],\n",
      "    \"external_id\": \"tayga_upos_skipgram_300_2_2019\",\n",
      "    \"handle\": \"http://vectors.nlpl.eu/repository/20/185.zip\",\n",
      "    \"id\": 185,\n",
      "    \"iterations\": 10,\n",
      "    \"vocabulary size\": 249565,\n",
      "    \"window\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir / \"meta.json\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195436 word vectors.\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_model_file = os.path.join(data_dir, 'model.txt')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_model_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word_, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        try:\n",
    "            word, _ = word_.split('_')\n",
    "        except ValueError:\n",
    "            embeddings_index[word_] = coefs\n",
    "        else:\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 901 words (91 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(vocabulary) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in vocabulary.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Активирую слой Embedding весами из скачанной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучу 2 одинаковый сети: с слоем Embedding, обучающимся с обучением сетки, и с слоем Embedding, у которого веса уже были предобучены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = to_categorical(df_train[\"class\"], num_classes)\n",
    "y_val = to_categorical(df_val[\"class\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3, activation=\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "355/355 [==============================] - 8s 23ms/step - loss: 0.6095 - accuracy: 0.6568 - val_loss: 0.5987 - val_accuracy: 0.6672\n",
      "Epoch 2/20\n",
      "355/355 [==============================] - 8s 22ms/step - loss: 0.5818 - accuracy: 0.6818 - val_loss: 0.5951 - val_accuracy: 0.6713\n",
      "Epoch 3/20\n",
      "355/355 [==============================] - 8s 23ms/step - loss: 0.5681 - accuracy: 0.6926 - val_loss: 0.5952 - val_accuracy: 0.6716\n",
      "Epoch 4/20\n",
      "355/355 [==============================] - 8s 22ms/step - loss: 0.5503 - accuracy: 0.7060 - val_loss: 0.5974 - val_accuracy: 0.6686\n",
      "Epoch 5/20\n",
      "355/355 [==============================] - 8s 21ms/step - loss: 0.5270 - accuracy: 0.7214 - val_loss: 0.6088 - val_accuracy: 0.6718\n",
      "Epoch 6/20\n",
      "355/355 [==============================] - 8s 24ms/step - loss: 0.4971 - accuracy: 0.7418 - val_loss: 0.6305 - val_accuracy: 0.6704\n",
      "Epoch 7/20\n",
      "355/355 [==============================] - 8s 23ms/step - loss: 0.4648 - accuracy: 0.7591 - val_loss: 0.6704 - val_accuracy: 0.6576\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=5)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with pre-trained weights\n",
    "model_ptw = Sequential()\n",
    "model_ptw.add(embedding_layer)\n",
    "model_ptw.add(Conv1D(128, 3, activation=\"relu\"))\n",
    "model_ptw.add(GlobalMaxPool1D())\n",
    "model_ptw.add(Dense(20, activation=\"relu\"))\n",
    "model_ptw.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ptw.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "355/355 [==============================] - 12s 33ms/step - loss: 0.6229 - accuracy: 0.6416 - val_loss: 0.6121 - val_accuracy: 0.6556\n",
      "Epoch 2/20\n",
      "355/355 [==============================] - 12s 33ms/step - loss: 0.5862 - accuracy: 0.6767 - val_loss: 0.6080 - val_accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "355/355 [==============================] - 12s 33ms/step - loss: 0.5662 - accuracy: 0.6926 - val_loss: 0.6100 - val_accuracy: 0.6606\n",
      "Epoch 4/20\n",
      "355/355 [==============================] - 12s 34ms/step - loss: 0.5439 - accuracy: 0.7076 - val_loss: 0.6174 - val_accuracy: 0.6577\n",
      "Epoch 5/20\n",
      "355/355 [==============================] - 12s 33ms/step - loss: 0.5250 - accuracy: 0.7201 - val_loss: 0.6403 - val_accuracy: 0.6526\n",
      "Epoch 6/20\n",
      "355/355 [==============================] - 11s 32ms/step - loss: 0.5016 - accuracy: 0.7355 - val_loss: 0.6442 - val_accuracy: 0.6571\n",
      "Epoch 7/20\n",
      "355/355 [==============================] - 12s 33ms/step - loss: 0.4819 - accuracy: 0.7466 - val_loss: 0.6735 - val_accuracy: 0.6529\n"
     ]
    }
   ],
   "source": [
    "history_ptw = model_ptw.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_ptw = model_ptw.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "1. Модели с предобученными весами и без показали одинаковый результат.\n",
    "2. Для обучения модели с предобученми весами необходимо на 43% больше времени, чем на модель, у которой веса обучаются вместе с сеткой."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dl-nlp-cnn1.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
